{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning with OpenAI Taxi-v2 \n",
    "<br> \n",
    "In this Notebook, we'll implement an agent <b>that plays OpenAI Taxi-V2.</b>\n",
    "\n",
    "The goal of this game is that our agent must <b>pick up the passenger at one location and drop him off to the goal as fast as possible.</b>\n",
    "\n",
    "There are 4 locations (labeled by different letters) and your job is to pick up the passenger at one location and drop him off in another. \n",
    "\n",
    "- You receive +20 points for a successful dropoff\n",
    "- Lose 1 point for every timestep it takes. \n",
    "- There is also a 10 point penalty for illegal pick-up and drop-off actions (if you don't drop the passenger in one of the 3 other locations)\n",
    "- There are 500 state, 25 location * 5 place where the passenger could be (Four special location and being in the taxi) * 4 destination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites \n",
    "Before diving on the notebook **you need to understand**:\n",
    "- The foundations of Reinforcement learning (MC, TD, Rewards hypothesis...) [Article](https://medium.freecodecamp.org/an-introduction-to-reinforcement-learning-4339519de419)\n",
    "- Q-learning [Article](https://medium.freecodecamp.org/diving-deeper-into-reinforcement-learning-with-q-learning-c18d0db58efe)\n",
    "- You can follow this notebook using my [video tutorial](https://www.youtube.com/watch?v=q2ZOEFAaaI0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Import the dependencies \n",
    "First, we need to import the libraries <b>that we'll need to create our agent.</b></br>\n",
    "We use 3 libraries:\n",
    "- `Numpy` for our Qtable\n",
    "- `OpenAI Gym` for our Taxi Environment\n",
    "- `Random` to generate random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create the environment \n",
    "- Here we'll create the Taxi environment. \n",
    "- OpenAI Gym is a library <b> composed of many environments that we can use to train our agents.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[35m\u001b[43mY\u001b[0m\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Taxi-v2\")\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create the Q-table and initialize it \n",
    "- Now, we'll create our Q-table, to know how much rows (states) and columns (actions) we need, we need to calculate the action_size and the state_size\n",
    "- OpenAI Gym provides us a way to do that: `env.action_space.n` and `env.observation_space.n`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action size  6\n",
      "State size  500\n"
     ]
    }
   ],
   "source": [
    "action_size = env.action_space.n\n",
    "print(\"Action size \", action_size)\n",
    "\n",
    "state_size = env.observation_space.n\n",
    "print(\"State size \", state_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "qtable = np.zeros((state_size, action_size))\n",
    "print(qtable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create the hyperparameters \n",
    "Here, we'll specify the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_episodes = 5000        # Total episodes the orig_value = 50000\n",
    "total_test_episodes = 100     # Total test episodes\n",
    "max_steps = 99                # Max steps per episode\n",
    "\n",
    "learning_rate = 0.7           # Learning rate\n",
    "gamma = 0.618                 # Discounting rate\n",
    "\n",
    "# Exploration parameters\n",
    "epsilon = 1.0                 # Exploration rate\n",
    "max_epsilon = 1.0             # Exploration probability at start\n",
    "min_epsilon = 0.01            # Minimum exploration probability \n",
    "decay_rate = 0.01             # Exponential decay rate for exploration prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: The Q-learning algorithm \n",
    "- Now we implement the Q learning algorithm:\n",
    "<img src=\"qtable_algo.png\" alt=\"Q algo\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rewards = []\n",
    "for epi in range(total_episodes):\n",
    "    state = env.reset()\n",
    "    step = 0\n",
    "    done = False\n",
    "    total_rewards = 0\n",
    "    for step in range(max_steps):\n",
    "        rand_or_not = random.uniform(0, 1)\n",
    "        if rand_or_not > epsilon:\n",
    "            action = np.argmax(qtable[state, :])\n",
    "        else:\n",
    "            action = env.action_space.sample()\n",
    "            \n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma * np.max(qtable[next_state, :]) - qtable[state, action])\n",
    "        total_rewards += reward\n",
    "        state = next_state\n",
    "        if done == True:\n",
    "            break\n",
    "    rewards.append(total_rewards)\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay_rate*epi)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(rewards)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards[-4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Use our Q-table to play Taxi \n",
    "- After 50 000 episodes, our Q-table can be used as a \"cheatsheet\" to play Taxi.\n",
    "- By running this cell you can see our agent playing Taxi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score over time: 8.39\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "rewards = []\n",
    "\n",
    "for episode in range(total_test_episodes):\n",
    "    state = env.reset()\n",
    "    step = 0\n",
    "    done = False\n",
    "    total_rewards = 0\n",
    "#     print(\"****************************************************\")\n",
    "#     print(\"EPISODE \", episode)\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        #env.render()\n",
    "        # Take the action (index) that have the maximum expected future reward given that state\n",
    "        action = np.argmax(qtable[state,:])\n",
    "        #action = env.action_space.sample() # To check the result of a random agent\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        total_rewards += reward\n",
    "        \n",
    "        if done:\n",
    "            rewards.append(total_rewards)\n",
    "            #print (\"Score\", total_rewards)\n",
    "            break\n",
    "        state = new_state\n",
    "#env.close()\n",
    "print (\"Score over time: \" +  str(sum(rewards)/total_test_episodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | :\u001b[43m \u001b[0m:\u001b[34;1mG\u001b[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "\n",
      "+---------+\n",
      "|R: | : :\u001b[34;1m\u001b[43mG\u001b[0m\u001b[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "+---------+\n",
      "|R: | : :\u001b[42mG\u001b[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "+---------+\n",
      "|R: | :\u001b[42m_\u001b[0m:G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : :\u001b[42m_\u001b[0m: |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : :\u001b[42m_\u001b[0m: |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : |\u001b[42m_\u001b[0m: |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35m\u001b[42mB\u001b[0m\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "# play one episode with visualiztion\n",
    "import time\n",
    "state = env.reset()\n",
    "step = 0\n",
    "done = False\n",
    "total_rewards = 0\n",
    "for step in range(max_steps):\n",
    "        env.render()\n",
    "        time.sleep(2)\n",
    "        action = np.argmax(qtable[state,:])\n",
    "        #action = env.action_space.sample() # To check the result of a random agent\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        state = next_state\n",
    "        total_rewards += reward\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "            \n",
    "print(total_rewards)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
